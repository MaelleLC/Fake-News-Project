{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIME LINE OF NEWS\n",
    "\n",
    "**Aim :** Look into the spreading of news over websites during time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "os.chdir(\"C:/Users/maell/Fake_News_Project\")\n",
    "\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import community\n",
    "\n",
    "from scipy import *\n",
    "\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data(fichier):\n",
    "    data = pd.read_csv(fichier,sep = '\\t',decimal = '.',index_col=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the day we want to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date='20170830'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlobalEventID</th>\n",
       "      <th>EventTimeDate</th>\n",
       "      <th>MentionTimeDate</th>\n",
       "      <th>MentionType</th>\n",
       "      <th>MentionSourceName</th>\n",
       "      <th>MentionIdentifier</th>\n",
       "      <th>SentenceID</th>\n",
       "      <th>Actor1CharOffset</th>\n",
       "      <th>Actor2CharOffset</th>\n",
       "      <th>ActionCharOffset</th>\n",
       "      <th>InRawText</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>MentionDocLen</th>\n",
       "      <th>MentionDocTone</th>\n",
       "      <th>MentionDocTranslationInfo</th>\n",
       "      <th>Extras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>573975381.0</td>\n",
       "      <td>2.016083e+13</td>\n",
       "      <td>2.017083e+13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>thereflector.com</td>\n",
       "      <td>http://www.thereflector.com/home_scene/article...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3641.0</td>\n",
       "      <td>3.001580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>574286833.0</td>\n",
       "      <td>2.016083e+13</td>\n",
       "      <td>2.017083e+13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>clarionledger.com</td>\n",
       "      <td>http://www.clarionledger.com/story/news/politi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2793.0</td>\n",
       "      <td>2869.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5090.0</td>\n",
       "      <td>0.937082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>573948616.0</td>\n",
       "      <td>2.016083e+13</td>\n",
       "      <td>2.017083e+13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>thejournal.ie</td>\n",
       "      <td>http://www.thejournal.ie/public-services-card-...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10662.0</td>\n",
       "      <td>10670.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>12130.0</td>\n",
       "      <td>-0.048591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>574218333.0</td>\n",
       "      <td>2.016083e+13</td>\n",
       "      <td>2.017083e+13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cbslocal.com</td>\n",
       "      <td>http://minnesota.cbslocal.com/2017/08/29/mpls-...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>1323.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>-5.761317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>685153804.0</td>\n",
       "      <td>2.017083e+13</td>\n",
       "      <td>2.017083e+13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>enca.com</td>\n",
       "      <td>https://www.enca.com/south-africa/checkpoint-t...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>-4.081633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GlobalEventID  EventTimeDate  MentionTimeDate  MentionType  \\\n",
       "0    573975381.0   2.016083e+13     2.017083e+13          1.0   \n",
       "1    574286833.0   2.016083e+13     2.017083e+13          1.0   \n",
       "2    573948616.0   2.016083e+13     2.017083e+13          1.0   \n",
       "3    574218333.0   2.016083e+13     2.017083e+13          1.0   \n",
       "4    685153804.0   2.017083e+13     2.017083e+13          1.0   \n",
       "\n",
       "   MentionSourceName                                  MentionIdentifier  \\\n",
       "0   thereflector.com  http://www.thereflector.com/home_scene/article...   \n",
       "1  clarionledger.com  http://www.clarionledger.com/story/news/politi...   \n",
       "2      thejournal.ie  http://www.thejournal.ie/public-services-card-...   \n",
       "3       cbslocal.com  http://minnesota.cbslocal.com/2017/08/29/mpls-...   \n",
       "4           enca.com  https://www.enca.com/south-africa/checkpoint-t...   \n",
       "\n",
       "   SentenceID  Actor1CharOffset  Actor2CharOffset  ActionCharOffset  \\\n",
       "0         6.0              -1.0            1409.0            1434.0   \n",
       "1        10.0              -1.0            2793.0            2869.0   \n",
       "2        36.0              -1.0           10662.0           10670.0   \n",
       "3         6.0              -1.0            1299.0            1323.0   \n",
       "4         2.0             285.0              -1.0             342.0   \n",
       "\n",
       "   InRawText  Confidence  MentionDocLen  MentionDocTone  \\\n",
       "0        0.0        40.0         3641.0        3.001580   \n",
       "1        1.0        50.0         5090.0        0.937082   \n",
       "2        0.0        40.0        12130.0       -0.048591   \n",
       "3        0.0        40.0         1408.0       -5.761317   \n",
       "4        0.0        40.0         1045.0       -4.081633   \n",
       "\n",
       "   MentionDocTranslationInfo  Extras  \n",
       "0                        NaN     NaN  \n",
       "1                        NaN     NaN  \n",
       "2                        NaN     NaN  \n",
       "3                        NaN     NaN  \n",
       "4                        NaN     NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file='all_data/all_data_'+date+'.csv'\n",
    "all_data=open_data(file)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the events of this day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of publication : 1729\n",
      "http://www.coloradodaily.com/business/ci_31258728/oskar-blues-halts-beer-production-longmont-can-water\n"
     ]
    }
   ],
   "source": [
    "# Count number of publication\n",
    "eventID=685157906\n",
    "data_event=all_data[all_data.GlobalEventID==eventID]\n",
    "print('Nb of publication :',len(data_event))\n",
    "print(data_event.MentionIdentifier[613738 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_event = Counter(all_data['GlobalEventID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_event.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a reduce DataFrame containning only the event we care about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "all_data_reduit=pd.DataFrame();\n",
    "index_to_drop=[]\n",
    "\n",
    "event_list=[685158048]\n",
    "\n",
    "for event in event_list: #all_data['GlobalEventID'].unique(): un peu long -> on fait que sur les events qu'on veut tracer\n",
    "    df_reduit=all_data[all_data['GlobalEventID']==event]\n",
    "    df_reduit.sort_values(by=['MentionTimeDate'],inplace=True)\n",
    "    for i in range (1,len(df_reduit)):\n",
    "        if df_reduit['MentionTimeDate'].iloc[i-1]==df_reduit['MentionTimeDate'].iloc[i]:\n",
    "            all_data_index=df_reduit.iloc[i].name\n",
    "            index_to_drop.append(all_data_index) #we drop the \"last\" -> never drop the \"0\"\n",
    "    all_data_reduit=all_data.drop(index_to_drop, inplace=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the graph of the event timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_event_timeline(date,list_event):\n",
    "    #ouverture du df\n",
    "    file='all_data_'+date+'.csv'\n",
    "    all_data=open_data(file)\n",
    "    \n",
    "    #correction du fd (suppression des lignes multiples (meme journal, meme event, meme horaire))\n",
    "    all_data_reduit=pd.DataFrame();\n",
    "    index_to_drop=[]\n",
    "    for event in list_event: #all_data['GlobalEventID'].unique(): un peu long -> on fait que sur les events qu'on veut tracer\n",
    "        df_reduit=all_data[all_data['GlobalEventID']==event]\n",
    "        df_reduit.sort_values(by=['MentionTimeDate'],inplace=True)\n",
    "        for i in range (1,len(df_reduit)):\n",
    "            if df_reduit['MentionTimeDate'].iloc[i-1]==df_reduit['MentionTimeDate'].iloc[i] and df_reduit['MentionSourceName'].iloc[i-1]==df_reduit['MentionSourceName'].iloc[i]:\n",
    "                all_data_index=df_reduit.iloc[i].name\n",
    "                index_to_drop.append(all_data_index) #we drop the \"last\" -> never drop the \"0\"\n",
    "    all_data_reduit=all_data.drop(index_to_drop, inplace=False)\n",
    "        \n",
    "    #creation du graph\n",
    "    DG=nx.DiGraph()\n",
    "    #pour chaque evenement que l'on souhaite regarder\n",
    "    for event in list_event:\n",
    "        #on récupère le df avec que cet evenement, et on le classe dans l'ordre d'apparition\n",
    "        df=all_data_reduit[all_data_reduit['GlobalEventID']==event]\n",
    "        \n",
    "        #on créer les noeuds\n",
    "        DG.add_nodes_from(df['MentionSourceName'])\n",
    "        \n",
    "        #on ajoute les liens\n",
    "        df.sort_values(['MentionTimeDate'], inplace=True)\n",
    "        list_time=list(df['MentionSourceName'])\n",
    "     \n",
    "        counter=1;\n",
    "        c_node=0;\n",
    "        for i in range (0,len(list_time)-1):\n",
    "            DG.add_edge(list_time[i],list_time[i+1],timeline=counter)\n",
    "            counter+=1\n",
    "            try :\n",
    "                DG.node[list_time[i]]['Time']\n",
    "            except:\n",
    "                DG.node[list_time[i]]['Time']=c_node\n",
    "                c_node+=1\n",
    "            \n",
    "    return(DG)\n",
    "###############################################################################################################################\n",
    "def label_controversial_website(G): #OK\n",
    "    fake_news_sources_df=pd.read_csv('Classification_Website_False.csv',sep = ';',decimal = '.')\n",
    "    fake_news_sources_df.set_index('url',inplace=True)\n",
    "    fake_news_sources=list(fake_news_sources_df.index.unique())\n",
    "    for node in list(G.nodes):\n",
    "        for site in fake_news_sources:\n",
    "            if node==site:\n",
    "                G.node[node]['Controversial Website']=fake_news_sources_df.loc[site].type\n",
    "    return (G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\maell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "DG=graph_event_timeline(date,[685157906]) #685158048])\n",
    "DG=label_controversial_website(DG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(DG,'event_685157906_day_20170830.gexf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study the event for interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitchy.com\n",
      "washingtonexaminer.com\n",
      "dailytelegraph.com.au\n",
      "thedailybeast.com\n",
      "patriotpost.us\n",
      "theblaze.com\n",
      "politicususa.com\n",
      "politicususa.com\n",
      "westernjournalism.com\n",
      "thinkprogress.org\n",
      "express.co.uk\n",
      "washingtonexaminer.com\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "fake_news_sources_df=pd.read_csv('Classification_Website_False.csv',sep = ';',decimal = '.')\n",
    "fake_news_sources_df.set_index('url',inplace=True)\n",
    "fake_news_sources=list(fake_news_sources_df.index.unique())\n",
    "\n",
    "for site in list(all_data_reduit[all_data_reduit['GlobalEventID']==685157906].MentionSourceName):\n",
    "    if site in fake_news_sources:\n",
    "        print(site)\n",
    "        c+=1\n",
    "        \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://k99country.iheart.com/content/2017-08-29-president-trump-arrives-in-coastal-bend-to-survey-hurricane-harvey-damage/'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[all_data['GlobalEventID']==685158928].MentionIdentifier[16144]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
